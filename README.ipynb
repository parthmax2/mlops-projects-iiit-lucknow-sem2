{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Let's first inspect the uploaded Jupyter Notebook and extract key details to prepare the README.\n",
        "import nbformat\n",
        "\n",
        "notebook_path = '/content/MSA24003-deep-learning-assignment-3.ipynb'\n",
        "\n",
        "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "    notebook = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Extract title, main objectives, and libraries used\n",
        "cells = notebook['cells']\n",
        "all_text = \"\"\n",
        "for cell in cells:\n",
        "    if cell['cell_type'] == 'markdown':\n",
        "        all_text += cell['source'] + \"\\n\\n\"\n",
        "    elif cell['cell_type'] == 'code':\n",
        "        all_text += \"# Code Block:\\n\" + ''.join(cell['source']) + \"\\n\\n\"\n",
        "\n",
        "# Return only the first 3000 characters for a quick summary\n",
        "all_text[:3000]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "WUU26LW8P3Hi",
        "outputId": "1284a41e-6efb-4bfe-f040-6c76f3613df5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Code Block:\\n# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load\\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\\n\\n# Input data files are available in the read-only \"../input/\" directory\\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\\n\\nimport os\\nfor dirname, _, filenames in os.walk(\\'/kaggle/input\\'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \\n# You can also write temporary files to /kaggle/temp/, but they won\\'t be saved outside of the current session\\n\\n# Code Block:\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers, models, datasets\\nfrom tensorflow.keras import optimizers\\nimport matplotlib.pyplot as plt\\n\\n# **Loading Fashion_mnist Dataset**\\n\\n# Code Block:\\n(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()\\n\\n# Preprecessing\\n\\n# Code Block:\\ntrain_images = train_images.astype(\\'float32\\') / 255.0\\ntest_images = test_images.astype(\\'float32\\') / 255.0\\n\\n# Code Block:\\ntrain_images = tf.expand_dims(train_images, axis=-1)\\ntest_images = tf.expand_dims(test_images, axis=-1)\\n\\n# Code Block:\\ntrain_images = tf.image.resize(train_images, [32, 32])\\ntest_images = tf.image.resize(test_images, [32, 32])\\n\\n# One-Hot-Encoding\\n\\n# Code Block:\\ntrain_labels = tf.keras.utils.to_categorical(train_labels, 10)\\ntest_labels = tf.keras.utils.to_categorical(test_labels, 10)\\n\\n# **Model**\\n\\n# Lenet\\n\\n# Code Block:\\ndef build_lenet5():\\n    model = models.Sequential([\\n        layers.Conv2D(6, (5, 5), activation=\\'tanh\\', input_shape=(32, 32, 1)),\\n        layers.AveragePooling2D((2, 2)),\\n        layers.Conv2D(16, (5, 5), activation=\\'tanh\\'),\\n        layers.AveragePooling2D((2, 2)),\\n        layers.Flatten(),\\n        layers.Dense(120, activation=\\'tanh\\'),\\n        layers.Dense(84, activation=\\'tanh\\'),\\n        layers.Dense(10, activation=\\'softmax\\')\\n    ])\\n    return model\\n\\n# Alexnet\\n\\n# Code Block:\\ndef build_alexnet():\\n    model = models.Sequential([\\n        layers.Conv2D(32, (3, 3), activation=\\'relu\\', padding=\\'same\\', input_shape=(32, 32, 1)),\\n        layers.MaxPooling2D((2, 2)),\\n        \\n        layers.Conv2D(64, (3, 3), activation=\\'relu\\', padding=\\'same\\'),\\n        layers.MaxPooling2D((2, 2)),\\n        \\n        layers.Conv2D(128, (3, 3), activation=\\'relu\\', padding=\\'same\\'),\\n        layers.Conv2D(128, (3, 3), activation=\\'relu\\', padding=\\'same\\'),\\n        layers.Conv2D(64, (3, 3), activation=\\'relu\\', padding=\\'same\\'),\\n        layers.MaxPooling2D((2, 2)),\\n        \\n        layers.Flatten(),\\n        layers.Dense(512, activation=\\'relu\\'),\\n        layers.Dropout(0.5),\\n        layers.Dens'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IBGSXOJNP3zG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}